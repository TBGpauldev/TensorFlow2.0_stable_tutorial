{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data\n",
      " (50000, 32, 32, 3)\n",
      "test_data\n",
      " (10000, 32, 32, 3)\n",
      "training_label\n",
      " (50000, 1)\n",
      "test_label\n",
      " (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(\"training_data\\n\", x_train.shape)\n",
    "print(\"test_data\\n\", x_test.shape)\n",
    "print(\"training_label\\n\", y_train.shape)\n",
    "print(\"test_label\\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_ = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "y_train_ = tf.reshape(tf.one_hot(y_train, 10), (-1, 10))\n",
    "\n",
    "\n",
    "print(x_train_.shape)\n",
    "print(y_train_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 32, 32, 3), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .batch(batch_size)\n",
    "    .shuffle(10000)\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(lambda x, y: \n",
    "                      (tf.math.divide(tf.cast(x, tf.float32), 255.0), \n",
    "                       tf.reshape(tf.one_hot(y, 10), (-1, 10))))\n",
    ")\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 32, 32, 3), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .batch(1000)\n",
    "    .shuffle(10000)\n",
    ")\n",
    "test_dataset = (\n",
    "    test_dataset.map(lambda x, y: \n",
    "                      (tf.math.divide(tf.cast(x, tf.float32), 255.0), \n",
    "                       tf.reshape(tf.one_hot(y, 10), (-1, 10))))\n",
    ")\n",
    "\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(out_channels, strides=1):\n",
    "    return L.Conv2D(out_channels, kernel_size=3, \n",
    "                    strides=strides, padding='same', use_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training flag\n",
    "`call` method of `L.BatchNormalization` need to have `traininig` flag because this method have different behavior between traning and evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual block\n",
    "class ResidualBlock(tf.keras.Model):\n",
    "    def __init__(self, out_channels, strides=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__(name='ResidualBlock')\n",
    "        self.conv1 = conv3x3(out_channels, strides)\n",
    "        self.bn1 = L.BatchNormalization(axis=-1)\n",
    "        self.relu = L.ReLU()\n",
    "        self.conv2 = conv3x3(out_channels)\n",
    "        self.bn2 = L.BatchNormalization(axis=-1)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out, training=training)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out, training=training)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.Sequential\n",
    "`call` method of `tf.keras.Sequential` have `training` flag. This flag affects all layers included by the `tf.keras.Sequential` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__(name='ResNet')\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(16)\n",
    "        self.bn = L.BatchNormalization(axis=-1)\n",
    "        self.relu = L.ReLU()\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = L.AvgPool2D(8)\n",
    "        self.flatten = L.Flatten()\n",
    "        self.fc = L.Dense(num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, strides=1):\n",
    "        downsample = None\n",
    "        if (strides != 1) or (self.in_channels != out_channels):\n",
    "            downsample = tf.keras.Sequential([\n",
    "                conv3x3(out_channels, strides=strides),\n",
    "                L.BatchNormalization(axis=-1)])\n",
    "        layers = []\n",
    "        layers.append(block(out_channels, strides, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels))\n",
    "        return tf.keras.Sequential(layers)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out, training=training)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out, training=training)\n",
    "        out = self.layer2(out, training=training)\n",
    "        out = self.layer3(out, training=training)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(ResidualBlock, [2, 2, 2])\n",
    "def loss_fn(y, y_pre):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(y, y_pre)\n",
    "#     return tf.keras.losses.categorical_crossentropy(y, y_pre)\n",
    "\n",
    "def accuracy(y, y_pre):\n",
    "    return tf.keras.metrics.categorical_accuracy(y, y_pre)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_120 (Conv2D)          multiple                  432       \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat multiple                  64        \n",
      "_________________________________________________________________\n",
      "re_lu_56 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_40 (Sequential)   multiple                  9472      \n",
      "_________________________________________________________________\n",
      "sequential_42 (Sequential)   multiple                  37504     \n",
      "_________________________________________________________________\n",
      "sequential_44 (Sequential)   multiple                  148736    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 196,858\n",
      "Trainable params: 195,738\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.8066 - categorical_accuracy: 0.7142\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.7177 - categorical_accuracy: 0.7469\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.6420 - categorical_accuracy: 0.7756\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.5751 - categorical_accuracy: 0.8006\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.5222 - categorical_accuracy: 0.8183\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.4657 - categorical_accuracy: 0.8395\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.4186 - categorical_accuracy: 0.8549\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.3823 - categorical_accuracy: 0.8679\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.3404 - categorical_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.3028 - categorical_accuracy: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a8a5f60cc0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 120ms/step - loss: 0.8489 - categorical_accuracy: 0.7268\n",
      "test_accracy:  0.7268\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print(\"test_accracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
