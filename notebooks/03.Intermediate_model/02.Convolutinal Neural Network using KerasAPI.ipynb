{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.Convolutinal Neural Network using KerasAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data\n",
      " (50000, 32, 32, 3)\n",
      "test_data\n",
      " (10000, 32, 32, 3)\n",
      "training_label\n",
      " (50000, 1)\n",
      "test_label\n",
      " (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(\"training_data\\n\", x_train.shape)\n",
    "print(\"test_data\\n\", x_test.shape)\n",
    "print(\"training_label\\n\", y_train.shape)\n",
    "print(\"test_label\\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_ = tf.transpose(tf.convert_to_tensor(x_train, dtype=tf.float32), \n",
    "                        [0, 3, 1, 2])\n",
    "y_train_ = tf.reshape(tf.one_hot(y_train, 10), (-1, 10))\n",
    "\n",
    "\n",
    "print(x_train_.shape)\n",
    "print(y_train_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((None, 3, 32, 32), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .batch(batch_size)\n",
    "    .shuffle(10000)\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(lambda x, y: \n",
    "                      (tf.math.divide(tf.cast(\n",
    "                          tf.transpose(x, [0, 3, 1, 2]), tf.float32), 255.0), \n",
    "                       tf.reshape(tf.one_hot(y, 10), (-1, 10))))\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((None, 3, 32, 32), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .batch(1000)\n",
    "    .shuffle(10000)\n",
    ")\n",
    "test_dataset = (\n",
    "    test_dataset.map(lambda x, y: \n",
    "                      (tf.math.divide(tf.cast(\n",
    "                          tf.transpose(x, [0, 3, 1, 2]), tf.float32), 255.0), \n",
    "                       tf.reshape(tf.one_hot(y, 10), (-1, 10))))\n",
    ")\n",
    "test_dataset = test_dataset.repeat()\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Cifar10Model, self).__init__(name='cifar_cnn')\n",
    "        \n",
    "        self.conv_block1 = tf.keras.Sequential([\n",
    "            L.Conv2D(\n",
    "                8, \n",
    "                5,\n",
    "                padding='same',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.001),\n",
    "                data_format=\"channels_first\"\n",
    "            ),\n",
    "            L.MaxPooling2D(\n",
    "                (3, 3), \n",
    "                (2, 2), \n",
    "                padding='same',\n",
    "                data_format=\"channels_first\"\n",
    "            ),\n",
    "            L.BatchNormalization(axis=1),\n",
    "        ])\n",
    "\n",
    "        self.conv_block2 = tf.keras.Sequential([\n",
    "            L.Conv2D(\n",
    "                16, \n",
    "                5,\n",
    "                padding='same',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.001),\n",
    "                data_format=\"channels_first\"\n",
    "            ),\n",
    "            L.MaxPooling2D(\n",
    "                (3, 3), \n",
    "                (2, 2), \n",
    "                padding='same',\n",
    "                data_format=\"channels_first\"\n",
    "            ),\n",
    "            L.BatchNormalization(axis=1),\n",
    "        ])\n",
    "        \n",
    "        self.conv_block3 = tf.keras.Sequential([\n",
    "            L.Conv2D(\n",
    "                32, \n",
    "                5,\n",
    "                padding='same',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.001),\n",
    "                data_format=\"channels_first\"\n",
    "            ),\n",
    "            L.MaxPooling2D(\n",
    "                (3, 3), \n",
    "                (2, 2), \n",
    "                padding='same',\n",
    "                data_format=\"channels_first\"\n",
    "            ),\n",
    "            L.BatchNormalization(axis=1),\n",
    "        ])\n",
    "        \n",
    "        self.flatten = L.Flatten()\n",
    "        self.fc1 = L.Dense(\n",
    "            256, \n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001))\n",
    "        self.dropout = L.Dropout(rate=0.8)\n",
    "        self.fc2 = L.Dense(10)\n",
    "        self.softmax = L.Softmax()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Cifar10Model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "y_init = model(x_train_[:100])\n",
    "y_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar_cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_9 (Sequential)    multiple                  640       \n",
      "_________________________________________________________________\n",
      "sequential_10 (Sequential)   multiple                  3280      \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   multiple                  12960     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  2570      \n",
      "_________________________________________________________________\n",
      "softmax_3 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 150,778\n",
      "Trainable params: 150,666\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train for 1562 steps\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "1562/1562 [==============================] - 8s 5ms/step - loss: 2.1312 - accuracy: 0.3173\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 7s 4ms/step - loss: 1.7109 - accuracy: 0.4451\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 7s 5ms/step - loss: 1.5162 - accuracy: 0.5227\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 7s 5ms/step - loss: 1.4080 - accuracy: 0.5708\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 7s 4ms/step - loss: 1.3424 - accuracy: 0.5992\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 7s 5ms/step - loss: 1.3027 - accuracy: 0.6153\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 7s 5ms/step - loss: 1.2747 - accuracy: 0.6342\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 7s 5ms/step - loss: 1.2453 - accuracy: 0.6501\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 7s 5ms/step - loss: 1.2249 - accuracy: 0.6602\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 7s 5ms/step - loss: 1.2093 - accuracy: 0.6677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b896158da0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    workers=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 5s 3ms/step - loss: 1.0771 - accuracy: 0.7102\n",
      "train_acc: 0.710\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.1741 - accuracy: 0.6766\n",
      "test_acc: 0.677\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_dataset, \n",
    "                                       steps=int(y_train.shape[0]/batch_size))\n",
    "print(\"train_acc: {:0.3f}\".format(train_acc))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset, \n",
    "                                     steps=int(y_test.shape[0]/1000))\n",
    "print(\"test_acc: {:0.3f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
